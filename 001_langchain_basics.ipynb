{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
      "metadata": {
        "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
      },
      "source": [
        "# Part1: Langchain 기초\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
      "metadata": {
        "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
      },
      "source": [
        "## 1. 환경 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
      "metadata": {
        "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
      },
      "source": [
        "### 1) 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
      "metadata": {
        "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
      "metadata": {
        "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
      },
      "source": [
        "### 2) OpenAI 인증키 설정\n",
        "https://openai.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b76f68a8-4745-4377-8057-6090b87377d1",
      "metadata": {
        "id": "b76f68a8-4745-4377-8057-6090b87377d1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
      "metadata": {
        "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
      },
      "source": [
        "## 2. LLM Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23729d10-9600-415b-b7d1-f954665224e3",
      "metadata": {
        "id": "23729d10-9600-415b-b7d1-f954665224e3"
      },
      "source": [
        "### 1) Prompt + LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "# chain 실행\n",
        "result = llm.invoke(\"지구의 자전 주기는?\")"
      ],
      "metadata": {
        "id": "on0y4xF8VoyE"
      },
      "id": "on0y4xF8VoyE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "WzcZy4PruV1n",
        "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
      },
      "id": "WzcZy4PruV1n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'지구의 자전 주기는 약 24시간으로, 하루에 한 번 지구가 자전하는 주기를 가지고 있습니다. 이는 지구의 자전속도가 일정하게 유지되기 때문에 발생하는 현상입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"You are an expert in astronomy. Answer the question. <Question>: {input}\")\n",
        "prompt"
      ],
      "metadata": {
        "id": "SeNi_VXqYD-b"
      },
      "id": "SeNi_VXqYD-b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "# chain 연결 (LCEL)\n",
        "chain = prompt | llm\n",
        "\n",
        "# chain 호출\n",
        "chain.invoke({\"input\": \"지구의 자전 주기는?\"})"
      ],
      "metadata": {
        "id": "01WLucSpYjZt"
      },
      "id": "01WLucSpYjZt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f42fc0d1-c7a1-48a1-8e26-9718a1443be4",
      "metadata": {
        "id": "f42fc0d1-c7a1-48a1-8e26-9718a1443be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9b391ac6-ebc1-4554-cb1f-48fb2775cbbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'지구의 자전 주기는 약 24시간입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# prompt + model + output parser\n",
        "prompt = ChatPromptTemplate.from_template(\"You are an expert in astronomy. Answer the question. <Question>: {input}\")\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# LCEL chaining\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chain 호출\n",
        "chain.invoke({\"input\": \"지구의 자전 주기는?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0188674-915f-41af-ac46-56f9f54289b0",
      "metadata": {
        "id": "b0188674-915f-41af-ac46-56f9f54289b0"
      },
      "source": [
        "### 2) Multiple Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
      "metadata": {
        "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'future'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "prompt1 = ChatPromptTemplate.from_template(\"translates {korean_word} to English.\")\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"explain {english_word} using oxford dictionary to me in Korean.\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "\n",
        "chain1.invoke({\"korean_word\":\"미래\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16718b76-f59d-48f7-906f-5d2371417803",
      "metadata": {
        "id": "16718b76-f59d-48f7-906f-5d2371417803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'미래는 미래에 일어날 일들에 대한 예상이나 계획으로 정의됩니다. 혹은 앞으로 있을 것들에 대한 전망이나 예상을 가리키기도 합니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "chain2 = (\n",
        "    {\"english_word\": chain1}\n",
        "    | prompt2\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain2.invoke({\"korean_word\":\"미래\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "668cb998-71fb-4fd9-a6f1-61aad022fa3e",
      "metadata": {
        "id": "668cb998-71fb-4fd9-a6f1-61aad022fa3e"
      },
      "source": [
        "## 3. Prompt\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16573676-6ba7-439a-a989-1e7d13420e95",
      "metadata": {
        "id": "16573676-6ba7-439a-a989-1e7d13420e95"
      },
      "source": [
        "### 1) PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096f63a1-6b04-4d1d-aaaf-c5a77c5d3ef2",
      "metadata": {
        "id": "096f63a1-6b04-4d1d-aaaf-c5a77c5d3ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5b420b69-9385-4433-d5fd-a45eecdc756e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 'name'과 'age'라는 두 개의 변수를 사용하는 프롬프트 템플릿을 정의\n",
        "template_text = \"안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\"\n",
        "\n",
        "# PromptTemplate 인스턴스를 생성\n",
        "prompt_template = PromptTemplate.from_template(template_text)\n",
        "\n",
        "# 템플릿에 값을 채워서 프롬프트를 완성\n",
        "filled_prompt = prompt_template.format(name=\"홍길동\", age=30)\n",
        "\n",
        "filled_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a314a0f-11f3-47f0-aed7-d405b837a273",
      "metadata": {
        "id": "4a314a0f-11f3-47f0-aed7-d405b837a273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268737fc-25ba-4353-a032-457e1eec49d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['age', 'language', 'name'], template='안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n{language}로 번역해주세요.')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
        "combined_prompt = (\n",
        "              prompt_template\n",
        "              + PromptTemplate.from_template(\"\\n\\n아버지를 아버지라 부를 수 없습니다.\")\n",
        "              + \"\\n\\n{language}로 번역해주세요.\"\n",
        ")\n",
        "\n",
        "combined_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca859903-85e4-4630-a173-fffabb24a766",
      "metadata": {
        "id": "ca859903-85e4-4630-a173-fffabb24a766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bac3eadf-b312-42f1-cbc4-5ea8cffc48c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n영어로 번역해주세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "combined_prompt.format(name=\"홍길동\", age=30, language=\"영어\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a96988-196b-4c6f-ac01-6f8c56386af3",
      "metadata": {
        "id": "63a96988-196b-4c6f-ac01-6f8c56386af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3d9dacbb-874a-4879-8a2b-f5eb8f61ce9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, my name is Hong Gildong and I am 30 years old.\\n\\nI cannot call my father \"father.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "chain = combined_prompt | llm | StrOutputParser()\n",
        "chain.invoke({\"age\":30, \"language\":\"영어\", \"name\":\"홍길동\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa617bbb-8ccb-4aab-a7df-6cd8232ac92f",
      "metadata": {
        "id": "aa617bbb-8ccb-4aab-a7df-6cd8232ac92f"
      },
      "source": [
        "### 2) ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10dc9e58-0555-49d1-9ea0-faba6bd63f55",
      "metadata": {
        "id": "10dc9e58-0555-49d1-9ea0-faba6bd63f55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9a2612-444f-4ee0-b2dd-254efe61e4ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.'),\n",
              " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1a8fcae-33bd-43d9-a55e-9f37e82f5484",
      "metadata": {
        "id": "f1a8fcae-33bd-43d9-a55e-9f37e82f5484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e1740b02-89a5-4e97-8fda-93fb46a238f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'태양계에서 가장 큰 행성은 목성입니다. 목성은 태양계에서 가장 많은 질량을 가지고 있으며, 지름도 가장 큽니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e332a435-3379-4b08-8800-2c758eea9eca",
      "metadata": {
        "id": "e332a435-3379-4b08-8800-2c758eea9eca"
      },
      "source": [
        "### 3) Message"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MessagePromptTemplate 활용\n",
        "\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate,  HumanMessagePromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(\"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "messages = chat_prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1bpbNOyINkM",
        "outputId": "bc9d550a-ff4c-4c8a-a4d0-4cf47b9f9e18"
      },
      "id": "u1bpbNOyINkM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.'),\n",
              " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oFv2sFWwLH3L",
        "outputId": "5bb23413-21e6-4f12-9434-d2cbdf23a4e8"
      },
      "id": "oFv2sFWwLH3L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'태양계에서 가장 큰 행성은 목성입니다. 목성은 태양 주위를 도는 행성 중에서 가장 크고 질량도 가장 많이 가지고 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f6cbd9-769e-4671-89cc-8fb3da5eca2d",
      "metadata": {
        "id": "62f6cbd9-769e-4671-89cc-8fb3da5eca2d"
      },
      "source": [
        "## 5. Model Parameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 모델 클래스 유형"
      ],
      "metadata": {
        "id": "OrGWildXSaQ7"
      },
      "id": "OrGWildXSaQ7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LLM"
      ],
      "metadata": {
        "id": "2xwl8LRsSkyX"
      },
      "id": "2xwl8LRsSkyX"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "llm.invoke(\"한국의 대표적인 관광지 3군데를 추천해주세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "MPNGvV1ASv4R",
        "outputId": "f49b9ee7-7ca3-4870-f7a3-7ac1e2fb8eef"
      },
      "id": "MPNGvV1ASv4R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1. 경복궁 (서울) - 대한민국의 대표적인 궁궐로, 조선 왕조의 건립 및 건축 양식을 보여주는 곳입니다. 아름다운 정원과 건물들이 많이 보존되어 있어서 한국의 역사와 문화를 체험할 수 있습니다.\\n\\n2. 제주도 (제주특별자치도) - 한국에서 가장 인기 있는 관광지로, 아름다운 자연경관과 독특한 문화, 맛집들이 많이 있는 곳입니다. 해변, 산, 화산, 동굴 등 다양한 자연 명소와 함께 제주 특유의 문화인 풍류와 제주 오일장 등을 즐길 수 있습니다.\\n\\n3. 부산 남포동 (부산) - 부산'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ChatModel"
      ],
      "metadata": {
        "id": "n4p-sPIXSp6u"
      },
      "id": "n4p-sPIXSp6u"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "chain = chat_prompt | chat\n",
        "chain.invoke({\"user_input\": \"안녕하세요? 한국의 대표적인 관광지 3군데를 추천해주세요.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoS6GNWQSwmF",
        "outputId": "46f9a6f7-da76-4556-dbf4-a5b283592781"
      },
      "id": "RoS6GNWQSwmF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요! 한국의 대표적인 관광지 3군데를 추천해드리겠습니다.\\n\\n1. 경복궁 (Gyeongbokgung Palace) - 서울의 중심에 위치한 경복궁은 조선 왕조의 궁궐로서 가장 크고 아름다운 궁궁 중 하나입니다. 경복궁에서는 한국 전통 건축물을 감상하고 궁중문화를 체험할 수 있습니다.\\n\\n2. 부산 해운대해수욕장 (Haeundae Beach) - 부산의 대표적인 해변으로 유명한 해운대해수욕장은 아름다운 모래사장과 시원한 바다를 즐길 수 있는 장소입니다. 해수욕뿐만 아니라 주변의 맛집과 관광명소도 풍부합니다.\\n\\n3. 경주 (Gyeongju) - 경주는 한국의 역사와 문화가 깃들어 있는 도시로서 세계문화유산에 등재된 고구려 유적지와 신라 왕궁, 불교 사찰 등이 있습니다. 경주는 한국의 역사적인 유산을 체험할 수 있는 멋진 관광지입니다.\\n\\n이렇게 한국의 대표적인 관광지 3군데를 추천해드렸습니다. 혹시 더 궁금한 사항이 있으시면 언제든지 물어보세요!')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f4f0d21-c236-41dc-906f-e2d58c02b1ea",
      "metadata": {
        "id": "9f4f0d21-c236-41dc-906f-e2d58c02b1ea"
      },
      "source": [
        "### 2) 모델 파라미터 설정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델에 직접 파라미터를 전달 (모델 생성 시점)"
      ],
      "metadata": {
        "id": "mkaCYK13oc4-"
      },
      "id": "mkaCYK13oc4-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f8cfed5-aa87-4c2a-b2fa-f2800fc8c140",
      "metadata": {
        "id": "5f8cfed5-aa87-4c2a-b2fa-f2800fc8c140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb22a71a-fe81-4c05-f3d5-a0090ea6431a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 139,822km로 태양계에서 가장 큰 행성이며, 대기 중에 수소와 헬륨 등의 기체가 풍부하게 존재하는 고대의 거대한 가스 행성입니다.'\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "params = {\n",
        "    \"temperature\": 0.7,         # 생성된 텍스트의 다양성 조정\n",
        "    \"max_tokens\": 100,          # 생성할 최대 토큰 수\n",
        "}\n",
        "\n",
        "kwargs = {\n",
        "    \"frequency_penalty\": 0.5,   # 이미 등장한 단어의 재등장 확률\n",
        "    \"presence_penalty\": 0.5,    # 새로운 단어의 도입을 장려\n",
        "    \"stop\": [\"\\n\"]              # 정지 시퀀스 설정\n",
        "\n",
        "}\n",
        "\n",
        "# 모델 인스턴스를 생성할 때 설정\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **params, model_kwargs = kwargs)\n",
        "\n",
        "\n",
        "# 모델 호출\n",
        "question = \"태양계에서 가장 큰 행성은 무엇인가요?\"\n",
        "response = model.invoke(input=question)\n",
        "\n",
        "# 전체 응답 출력\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델에 직접 파라미터를 전달 (모델 호출 시점)"
      ],
      "metadata": {
        "id": "yAxlgzozpGMt"
      },
      "id": "yAxlgzozpGMt"
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 설정\n",
        "params = {\n",
        "    \"temperature\": 0.7,         # 생성된 텍스트의 다양성 조정\n",
        "    \"max_tokens\": 10,          # 생성할 최대 토큰 수\n",
        "}\n",
        "\n",
        "# 모델 인스턴스를 호출할 때 전달\n",
        "response = model.invoke(input=question, **params)\n",
        "\n",
        "# 문자열 출력\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9nGM_MroWwS",
        "outputId": "068c4d4d-8e76-4fee-cb02-1fa0c6fcbce0"
      },
      "id": "e9nGM_MroWwS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "태양계에서 가장 큰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd39280c-2de0-49bf-8ee9-51362d50b6cb",
      "metadata": {
        "id": "bd39280c-2de0-49bf-8ee9-51362d50b6cb"
      },
      "source": [
        "#### 모델에 추가적인 파라미터를 전달\n",
        "- bind 메서드를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec858125-f9ec-447c-ad84-c69f81399e91",
      "metadata": {
        "id": "ec858125-f9ec-447c-ad84-c69f81399e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2be864-c288-47ca-ad2c-f28d831ba63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='가장 큰 행성은 목성입니다. 목성은 태양계에서 가장 크고 질량이 가장 큰 행성으로, 지름은 약 14만 2000km에 달합니다.'\n",
            "content='태양계에서 가장 큰'\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=100)\n",
        "\n",
        "messages = prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "\n",
        "before_answer = model.invoke(messages)\n",
        "\n",
        "# # binding 이전 출력\n",
        "print(before_answer)\n",
        "\n",
        "# 모델 호출 시 추가적인 인수를 전달하기 위해 bind 메서드 사용 (응답의 최대 길이를 10 토큰으로 제한)\n",
        "chain = prompt | model.bind(max_tokens=10)\n",
        "\n",
        "after_answer = chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})\n",
        "\n",
        "# binding 이후 출력\n",
        "print(after_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5578014-f828-45e7-bd15-dde39ea72413",
      "metadata": {
        "id": "f5578014-f828-45e7-bd15-dde39ea72413"
      },
      "source": [
        "## 6. Output Parsers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aff3bd5-1dc0-4b60-ae36-78336bfa927d",
      "metadata": {
        "id": "8aff3bd5-1dc0-4b60-ae36-78336bfa927d"
      },
      "source": [
        "### 1) CSV Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5670c36-abbe-4f33-a736-87fbb2d8e72a",
      "metadata": {
        "id": "e5670c36-abbe-4f33-a736-87fbb2d8e72a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0cc555-fbd4-4a89-cb82-ab05421aa30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "762747bc-6a62-4d93-b052-15fb7443cf41",
      "metadata": {
        "id": "762747bc-6a62-4d93-b052-15fb7443cf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a107386-f676-43a7-d9d5-fe598d7c260f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bibimbap', 'Kimchi', 'Bulgogi', 'Japchae', 'Tteokbokki']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List five {subject}.\\n{format_instructions}\",\n",
        "    input_variables=[\"subject\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"subject\": \"popular Korean cusine\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b861abc3-570c-43f4-8a65-84dbc755b3f2",
      "metadata": {
        "id": "b861abc3-570c-43f4-8a65-84dbc755b3f2"
      },
      "source": [
        "### 2) JSON Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f633514f-f8e3-4c16-8fce-2c65fc28a5aa",
      "metadata": {
        "id": "f633514f-f8e3-4c16-8fce-2c65fc28a5aa"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "# 자료구조 정의 (pydantic)\n",
        "class CusineRecipe(BaseModel):\n",
        "    name: str = Field(description=\"name of a cusine\")\n",
        "    recipe: str = Field(description=\"recipe to cook the cusine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce40ce61-056b-4511-8c19-bfff7db60342",
      "metadata": {
        "id": "ce40ce61-056b-4511-8c19-bfff7db60342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12cc60f1-22c3-473a-db4a-533da6968ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"name of a cusine\", \"type\": \"string\"}, \"recipe\": {\"title\": \"Recipe\", \"description\": \"recipe to cook the cusine\", \"type\": \"string\"}}, \"required\": [\"name\", \"recipe\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# 출력 파서 정의\n",
        "output_parser = JsonOutputParser(pydantic_object=CusineRecipe)\n",
        "\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b14fb66-640e-4ff9-9826-bf4718dcd7a2",
      "metadata": {
        "id": "1b14fb66-640e-4ff9-9826-bf4718dcd7a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d0738f-c720-4369-8b1b-67d802d56363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['query'] partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"name of a cusine\", \"type\": \"string\"}, \"recipe\": {\"title\": \"Recipe\", \"description\": \"recipe to cook the cusine\", \"type\": \"string\"}}, \"required\": [\"name\", \"recipe\"]}\\n```'} template='Answer the user query.\\n{format_instructions}\\n{query}\\n'\n"
          ]
        }
      ],
      "source": [
        "# prompt 구성\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f42224e-a931-4fb1-868f-d4ed98489744",
      "metadata": {
        "id": "1f42224e-a931-4fb1-868f-d4ed98489744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f0f06c-ee25-4bde-cc91-a48cacf7bcc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Bibimbap',\n",
              " 'recipe': 'Bibimbap is a Korean mixed rice dish. To cook Bibimbap, you will need the following ingredients: cooked rice, vegetables (such as spinach, bean sprouts, carrots, zucchini, mushrooms), beef or tofu, eggs, sesame oil, soy sauce, sugar, garlic, and Korean red pepper paste (gochujang). To prepare Bibimbap, sauté the vegetables separately,'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "chain = prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"query\": \"Let me know how to cook Bibimbap\"})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}